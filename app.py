import streamlit as st
import os
import docx
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import google.generativeai as genai

# ==========================================
# 1. API KEY å¯«æ­»è¨­å®š
# ==========================================
MY_API_KEY = "AIzaSyBVF_HR40eAuH_MmevkgWe5E33Ielm0eCw" 
genai.configure(api_key=MY_API_KEY)

# å‘é‡æ¨¡å‹åç¨±
EMBEDDING_MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'

# --- æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

@st.cache_resource
def load_embedding_model():
    return SentenceTransformer(EMBEDDING_MODEL_NAME)

@st.cache_resource
def create_faiss_index(_embeddings):
    d = _embeddings.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(_embeddings)
    return index

def load_documents(folder_path):
    """åªè®€å– .docx æª”æ¡ˆï¼Œé¿å… .doc å°è‡´çš„éŒ¯èª¤"""
    doc_texts, doc_names = [], []
    files = [f for f in os.listdir(folder_path) if f.endswith('.docx') and not f.startswith('~$')]
    for filename in files:
        try:
            full_path = os.path.join(folder_path, filename)
            doc = docx.Document(full_path)
            full_text = "\n\n".join([para.text for para in doc.paragraphs if para.text.strip()])
            doc_texts.append(full_text)
            doc_names.append(filename)
        except Exception as e:
            st.error(f"è®€å– {filename} å‡ºéŒ¯: {e}")
    return doc_names, doc_texts

def split_text(doc_names, doc_texts):
    chunks, chunk_sources = [], []
    for i, text in enumerate(doc_texts):
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        chunks.extend(paragraphs)
        chunk_sources.extend([doc_names[i]] * len(paragraphs))
    return chunks, chunk_sources

def get_best_model_name():
    """æœ€çµ‚åµéŒ¯æ­¥é©Ÿï¼šå‹•æ…‹å°‹æ‰¾å¯ç”¨çš„ Gemini æ¨¡å‹åç¨±"""
    try:
        for m in genai.list_models():
            # å„ªå…ˆå°‹æ‰¾ 1.5-flashï¼Œè‹¥ç„¡å‰‡æ‰¾ 1.5-pro
            if 'gemini-1.5-flash' in m.name.lower():
                return m.name
        return "gemini-1.5-flash" # ä¿åº•
    except:
        return "gemini-1.5-flash"

def generate_answer(query, context):
    """èª¿ç”¨åµæ¸¬åˆ°çš„æ­£ç¢ºæ¨¡å‹åç¨±"""
    target_model = get_best_model_name()
    prompt = f"ä½ æ˜¯ä¸€ä½æ”¾é›»æ©ŸåŠ©æ‰‹ã€‚è«‹æ ¹æ“šæ‰‹å†Šå›ç­”å•é¡Œï¼š\n\n{context}\n\nå•é¡Œï¼š{query}\nå›ç­”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ï¼š"
    
    try:
        model = genai.GenerativeModel(target_model)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ç”¢ç”Ÿç­”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\n(å˜—è©¦ä½¿ç”¨çš„æ¨¡å‹åç¨±ç‚º: {target_model})"

# --- åˆå§‹åŒ– ---
st.set_page_config(page_title="æ”¾é›»æ©Ÿ AI åŠ©ç†", layout="centered")
st.title("âš¡ æ”¾é›»æ©Ÿæ“ä½œ AI å°å¹«æ‰‹ (Debug ç‰ˆ)")

if 'initialized' not in st.session_state:
    with st.spinner("ç³»çµ±åˆå§‹åŒ–ä¸­..."):
        st.session_state.model = load_embedding_model()
        current_folder = os.path.dirname(os.path.abspath(__file__))
        doc_names, doc_texts = load_documents(current_folder)
        
        if not doc_texts:
            st.error("æ‰¾ä¸åˆ° .docx æª”æ¡ˆï¼è«‹ç¢ºèªå·²å°‡ .doc å¦å­˜ç‚º .docx ä¸¦ä¸Šå‚³ã€‚")
            st.stop()
            
        chunks, _ = split_text(doc_names, doc_texts)
        embeddings = st.session_state.model.encode(chunks)
        st.session_state.chunks = chunks
        st.session_state.faiss_index = create_faiss_index(np.array(embeddings))
        st.session_state.initialized = True
        st.success(f"âœ… å·²è¼‰å…¥ {len(doc_names)} ä»½æ‰‹å†Šã€‚")

# --- UI ---
query = st.text_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š")
if st.button("è©¢å•"):
    if query:
        with st.spinner("åˆ†æä¸­..."):
            query_embedding = st.session_state.model.encode([query])
            _, indices = st.session_state.faiss_index.search(query_embedding, 5)
            context = "\n\n".join([st.session_state.chunks[i] for i in indices[0]])
            answer = generate_answer(query, context)
            st.markdown("### ğŸ¤– å›ç­”ï¼š")
            st.info(answer)

# --- æœ€çµ‚åµéŒ¯è³‡è¨Š (Debug Info) ---
with st.expander("ğŸ› ï¸ ç³»çµ±è¨ºæ–·è³‡è¨Š (æœ€çµ‚åµéŒ¯æ­¥é©Ÿ)"):
    st.write(f"ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹åç¨±: `{get_best_model_name()}`")
    st.write(f"å·²è¼‰å…¥çš„æ®µè½æ•¸é‡: {len(st.session_state.chunks)}")
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        st.write("æ‚¨çš„ API Key å¯ç”¨çš„æ¨¡å‹æ¸…å–®ï¼š")
        st.json(models)
    except Exception as e:
        st.write(f"ç„¡æ³•ç²å–æ¨¡å‹æ¸…å–®: {e}")