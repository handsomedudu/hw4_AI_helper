import streamlit as st
import os
import docx
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import google.generativeai as genai
import time

# --- 1. å¾ Secrets å®‰å…¨è®€å– API Key ---
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("âŒ éŒ¯èª¤ï¼šæœªåœ¨ Streamlit Secrets ä¸­æ‰¾åˆ° GOOGLE_API_KEYã€‚")
    st.stop()

EMBEDDING_MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'

@st.cache_resource
def load_embedding_model():
    return SentenceTransformer(EMBEDDING_MODEL_NAME)

@st.cache_resource
def create_faiss_index(_embeddings):
    d = _embeddings.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(_embeddings)
    return index

def load_documents(folder_path):
    doc_texts, doc_names = [], []
    files = [f for f in os.listdir(folder_path) if f.endswith('.docx') and not f.startswith('~$')]
    for filename in files:
        try:
            full_path = os.path.join(folder_path, filename)
            doc = docx.Document(full_path)
            full_text = "\n\n".join([para.text for para in doc.paragraphs if para.text.strip()])
            doc_texts.append(full_text)
            doc_names.append(filename)
        except Exception as e:
            st.error(f"è®€å– {filename} å‡ºéŒ¯: {e}")
    return doc_names, doc_texts

def generate_answer(query, context):
    """å…·å‚™è‡ªå‹•åˆ‡æ›æ¨¡å‹çš„ç”Ÿæˆå‡½å¼"""
    # å˜—è©¦æ¨¡å‹å„ªå…ˆé †åº
    model_candidates = ["models/gemini-1.5-flash", "models/gemini-2.0-flash", "models/gemini-pro"]
    
    prompt = f"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ”¾é›»æ©ŸåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”å•é¡Œï¼Œè‹¥ç„¡ç­”æ¡ˆè«‹èªªä¸çŸ¥é“ï¼š\n\n{context}\n\nå•é¡Œï¼š{query}\nå›ç­”ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ï¼š"

    last_error = ""
    for model_name in model_candidates:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text, model_name
        except Exception as e:
            last_error = str(e)
            if "429" in last_error:
                # å¦‚æœæ˜¯é…é¡å•é¡Œï¼Œå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹
                continue
            else:
                return f"ç™¼ç”ŸéŒ¯èª¤ï¼š{last_error}", model_name

    return f"æ‰€æœ‰å¯ç”¨æ¨¡å‹é…é¡çš†å·²è€—ç›¡ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚æœ€å¾ŒéŒ¯èª¤ï¼š{last_error}", "None"

# --- åˆå§‹åŒ– ---
st.set_page_config(page_title="æ”¾é›»æ©Ÿ AI åŠ©ç†", page_icon="âš¡")
st.title("âš¡ æ”¾é›»æ©Ÿæ“ä½œ AI å°å¹«æ‰‹")

if 'initialized' not in st.session_state:
    with st.spinner("ç³»çµ±åˆ†ææ–‡ä»¶ä¸­..."):
        st.session_state.model = load_embedding_model()
        current_folder = os.path.dirname(os.path.abspath(__file__))
        doc_names, doc_texts = load_documents(current_folder)
        
        if not doc_texts:
            st.error("æ‰¾ä¸åˆ° .docx æª”æ¡ˆï¼")
            st.stop()
            
        paragraphs = []
        for text in doc_texts:
            paragraphs.extend([p.strip() for p in text.split('\n\n') if p.strip()])
        
        embeddings = st.session_state.model.encode(paragraphs)
        st.session_state.chunks = paragraphs
        st.session_state.faiss_index = create_faiss_index(np.array(embeddings))
        st.session_state.initialized = True

# --- UI ---
query = st.text_input("è«‹è¼¸å…¥æ“ä½œå•é¡Œï¼š")
if st.button("è©¢å• AI"):
    if query:
        with st.spinner("æœå°‹ç­”æ¡ˆä¸­..."):
            query_embedding = st.session_state.model.encode([query])
            _, indices = st.session_state.faiss_index.search(query_embedding, 5)
            context = "\n\n".join([st.session_state.chunks[i] for i in indices[0]])
            
            answer, used_model = generate_answer(query, context)
            st.markdown(f"### ğŸ¤– AI çš„å›ç­” (ä½¿ç”¨æ¨¡å‹: {used_model})")
            st.info(answer)